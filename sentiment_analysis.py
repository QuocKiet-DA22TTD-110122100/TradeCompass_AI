"""
Ph·∫ßn 1: Ph√¢n t√≠ch Sentiment t·ª´ tin t·ª©c
S·ª≠ d·ª•ng: python sentiment_analysis.py
"""

import requests
from datetime import datetime, timedelta
import re
import os

# T·ª´ ƒëi·ªÉn sentiment ti·∫øng Vi·ªát cho ch·ª©ng kho√°n
POSITIVE_WORDS = [
    "tƒÉng", "tƒÉng tr∆∞·ªüng", "l·ª£i nhu·∫≠n", "k·ª∑ l·ª•c", "ƒë·ªôt ph√°", "b·ª©t ph√°",
    "kh·ªüi s·∫Øc", "t√≠ch c·ª±c", "l·∫°c quan", "h·ªìi ph·ª•c", "v∆∞·ª£t", "cao nh·∫•t",
    "th·∫Øng", "th√†nh c√¥ng", "hi·ªáu qu·∫£", "m·∫°nh", "v·ªØng", "·ªïn ƒë·ªãnh",
    "c∆° h·ªôi", "ti·ªÅm nƒÉng", "tri·ªÉn v·ªçng", "khuy·∫øn ngh·ªã mua", "outperform",
    "n√¢ng m·ª•c ti√™u", "doanh thu tƒÉng", "c·ªï t·ª©c", "chia th∆∞·ªüng",
    "h·ª£p ƒë·ªìng l·ªõn", "m·ªü r·ªông", "ƒë·∫ßu t∆∞", "ph√°t tri·ªÉn", "t·ªët"
]

NEGATIVE_WORDS = [
    "gi·∫£m", "s·ª•t", "l·ªó", "thua", "th·∫•p nh·∫•t", "ƒë√°y", "suy gi·∫£m",
    "ti√™u c·ª±c", "bi quan", "r·ªßi ro", "c·∫£nh b√°o", "lo ng·∫°i", "kh√≥ khƒÉn",
    "y·∫øu", "b√°n th√°o", "tho√°i v·ªën", "n·ª£", "ph√° s·∫£n", "ƒëi·ªÅu tra",
    "vi ph·∫°m", "x·ª≠ ph·∫°t", "ƒë√¨nh ch·ªâ", "h·ªßy ni√™m y·∫øt", "khuy·∫øn ngh·ªã b√°n",
    "underperform", "h·∫° m·ª•c ti√™u", "doanh thu gi·∫£m", "c·∫Øt gi·∫£m",
    "sa th·∫£i", "ƒë√≥ng c·ª≠a", "thua l·ªó", "x·∫•u"
]

def analyze_text_sentiment(text: str) -> dict:
    """Ph√¢n t√≠ch sentiment c·ªßa m·ªôt ƒëo·∫°n text"""
    text_lower = text.lower()
    
    positive_count = sum(1 for word in POSITIVE_WORDS if word in text_lower)
    negative_count = sum(1 for word in NEGATIVE_WORDS if word in text_lower)
    
    total = positive_count + negative_count
    if total == 0:
        score = 0
        label = "TRUNG TINH"
    else:
        score = (positive_count - negative_count) / total
        if score > 0.2:
            label = "TICH CUC"
        elif score < -0.2:
            label = "TIEU CUC"
        else:
            label = "TRUNG TINH"
    
    return {
        "score": score,
        "label": label,
        "positive_count": positive_count,
        "negative_count": negative_count
    }

def search_news_google(symbol: str, company_name: str = "") -> list:
    """T√¨m tin t·ª©c t·ª´ Google News RSS (kh√¥ng c·∫ßn API key)"""
    search_query = f"{symbol} c·ªï phi·∫øu {company_name}".strip()
    search_query = search_query.replace(" ", "+")
    
    url = f"https://news.google.com/rss/search?q={search_query}&hl=vi&gl=VN&ceid=VN:vi"
    
    try:
        response = requests.get(url, timeout=10)
        if response.status_code == 200:
            # Parse RSS ƒë∆°n gi·∫£n
            content = response.text
            
            # T√¨m c√°c item trong RSS
            items = re.findall(r'<item>(.*?)</item>', content, re.DOTALL)
            
            news_list = []
            for item in items[:10]:  # L·∫•y 10 tin m·ªõi nh·∫•t
                title_match = re.search(r'<title>(.*?)</title>', item)
                link_match = re.search(r'<link>(.*?)</link>', item)
                date_match = re.search(r'<pubDate>(.*?)</pubDate>', item)
                
                if title_match:
                    title = title_match.group(1)
                    # Lo·∫°i b·ªè CDATA
                    title = re.sub(r'<!\[CDATA\[(.*?)\]\]>', r'\1', title)
                    
                    news_list.append({
                        "title": title,
                        "link": link_match.group(1) if link_match else "",
                        "date": date_match.group(1) if date_match else ""
                    })
            
            return news_list
    except Exception as e:
        print(f"Loi khi lay tin tuc: {e}")
    
    return []

def get_sample_news(symbol: str) -> list:
    """Tin t·ª©c m·∫´u ƒë·ªÉ test khi kh√¥ng c√≥ internet"""
    sample_news = {
        "FPT": [
            {"title": "FPT ƒë·∫°t doanh thu k·ª∑ l·ª•c, l·ª£i nhu·∫≠n tƒÉng 20%", "date": "2024-01-10"},
            {"title": "FPT k√Ω h·ª£p ƒë·ªìng l·ªõn v·ªõi ƒë·ªëi t√°c Nh·∫≠t B·∫£n", "date": "2024-01-09"},
            {"title": "C·ªï phi·∫øu FPT ƒë∆∞·ª£c khuy·∫øn ngh·ªã mua v·ªõi ti·ªÅm nƒÉng tƒÉng tr∆∞·ªüng", "date": "2024-01-08"},
        ],
        "VNM": [
            {"title": "Vinamilk c√¥ng b·ªë chia c·ªï t·ª©c ti·ªÅn m·∫∑t", "date": "2024-01-10"},
            {"title": "VNM m·ªü r·ªông th·ªã tr∆∞·ªùng xu·∫•t kh·∫©u", "date": "2024-01-09"},
        ],
        "VCB": [
            {"title": "Vietcombank b√°o l√£i k·ª∑ l·ª•c nƒÉm 2023", "date": "2024-01-10"},
            {"title": "VCB ƒë∆∞·ª£c n√¢ng h·∫°ng t√≠n nhi·ªám", "date": "2024-01-09"},
        ],
        "DEFAULT": [
            {"title": "Th·ªã tr∆∞·ªùng ch·ª©ng kho√°n Vi·ªát Nam kh·ªüi s·∫Øc", "date": "2024-01-10"},
            {"title": "VN-Index h·ªìi ph·ª•c m·∫°nh trong phi√™n giao d·ªãch", "date": "2024-01-09"},
        ]
    }
    
    return sample_news.get(symbol, sample_news["DEFAULT"])

def analyze_stock_sentiment(symbol: str, use_sample: bool = False) -> dict:
    """Ph√¢n t√≠ch sentiment t·ªïng h·ª£p cho 1 m√£ c·ªï phi·∫øu"""
    
    print(f"\nDang tim tin tuc cho {symbol}...")
    
    if use_sample:
        news_list = get_sample_news(symbol)
    else:
        news_list = search_news_google(symbol)
        if not news_list:
            print("Khong tim thay tin tuc online, su dung tin mau...")
            news_list = get_sample_news(symbol)
    
    if not news_list:
        return {"error": "Khong tim thay tin tuc"}
    
    # Ph√¢n t√≠ch t·ª´ng tin
    results = []
    total_score = 0
    
    print(f"\n--- TIN TUC VA SENTIMENT ({symbol}) ---\n")
    
    for i, news in enumerate(news_list, 1):
        sentiment = analyze_text_sentiment(news["title"])
        results.append({
            "title": news["title"],
            "date": news.get("date", ""),
            "sentiment": sentiment
        })
        total_score += sentiment["score"]
        
        # Hi·ªÉn th·ªã
        emoji = "üü¢" if sentiment["label"] == "TICH CUC" else ("üî¥" if sentiment["label"] == "TIEU CUC" else "‚ö™")
        print(f"{i}. {emoji} [{sentiment['label']}]")
        print(f"   {news['title'][:80]}...")
        print()
    
    # T√≠nh sentiment trung b√¨nh
    avg_score = total_score / len(results) if results else 0
    
    if avg_score > 0.15:
        overall_label = "TICH CUC"
        recommendation = "Tin tuc ho tro - Co the xem xet MUA"
    elif avg_score < -0.15:
        overall_label = "TIEU CUC"
        recommendation = "Tin tuc tieu cuc - CAN THAN"
    else:
        overall_label = "TRUNG TINH"
        recommendation = "Tin tuc trung tinh - THEO DOI"
    
    summary = {
        "symbol": symbol,
        "news_count": len(results),
        "avg_score": avg_score,
        "overall_label": overall_label,
        "recommendation": recommendation,
        "positive_news": sum(1 for r in results if r["sentiment"]["label"] == "TICH CUC"),
        "negative_news": sum(1 for r in results if r["sentiment"]["label"] == "TIEU CUC"),
        "neutral_news": sum(1 for r in results if r["sentiment"]["label"] == "TRUNG TINH"),
    }
    
    return summary

def print_summary(summary: dict):
    """In t·ªïng k·∫øt sentiment"""
    print(f"\n{'='*50}")
    print(f"   TONG KET SENTIMENT: {summary['symbol']}")
    print(f"{'='*50}")
    print(f"  So tin phan tich: {summary['news_count']}")
    print(f"  Tin tich cuc: {summary['positive_news']}")
    print(f"  Tin tieu cuc: {summary['negative_news']}")
    print(f"  Tin trung tinh: {summary['neutral_news']}")
    print(f"  Diem sentiment: {summary['avg_score']:.2f} (-1 den +1)")
    print(f"  Danh gia: {summary['overall_label']}")
    print(f"\n  >>> {summary['recommendation']} <<<")

if __name__ == "__main__":
    data_dir = "data"
    if os.path.exists(data_dir):
        csv_files = [f.replace(".csv", "") for f in os.listdir(data_dir) if f.endswith(".csv")]
        print("Cac ma co phieu da tai:")
        print(", ".join(csv_files))
    
    symbol = input("\nNhap ma co phieu (VD: FPT): ").strip().upper()
    
    print("\nChon nguon tin:")
    print("1. Tim tin tuc online (Google News)")
    print("2. Su dung tin mau (de test)")
    
    choice = input("Lua chon (1/2): ").strip()
    use_sample = choice == "2"
    
    summary = analyze_stock_sentiment(symbol, use_sample)
    
    if "error" not in summary:
        print_summary(summary)
